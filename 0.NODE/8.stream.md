The concept of streams in computing usually describes the delivery of data in a steady, continuous flow. You can use streams for reading from or writing to a source continuously, thus eliminating the need to fit all the data in memory at once.

Using streams provides two major advantages. One is that you can use your memory efficiently since you do not have to load all the data into memory before you can begin processing. Another advantage is that using streams is time-efficient. You can start processing data almost immediately instead of waiting for the entire payload. These advantages make streams a suitable tool for large data transfer in I/O operations. Files are a collection of bytes that contain some data. Since files are a common data source in Node.js, streams can provide an efficient way to work with files in Node.js.

Node.js provides a streaming API in the stream module, a core Node.js module, for working with streams. All Node.js streams are an instance of the EventEmitter class.

1. There are four different kinds of streams in Node.js. They are:

- Readable streams: streams you can read data from.
- Writable streams: streams you can write data to.
- Duplex streams: streams you can read from and write to (usually simultaneously).
- Transform streams: a duplex stream in which the output (or writable stream) is dependent on the modification of the input (or readable stream).

When you run a Node.js script on the command-line, several command-line arguments are passed when the Node.js process runs. You can access these arguments using the argv property or the Node.js process. The argv property is an array that contains the command-line arguments passed to a Node.js script. In the second line, you assign that property to a variable called args.

## Reading a File with createReadStream()

The read command in the command-line application will read a file from the file system and print it out to the terminal similar to the cat command in a Linux-based terminal. In this section, you will implement that functionality using createReadStream() from the fs module.

The createReadStream function creates a readable stream that emits events that you can listen to since it inherits from the EventsEmitter class. The data event is one of these events. Every time the readable stream reads a piece of data, it emits the data event, releasing a piece of data.
When used with a callback function, it invokes the callback with that piece of data or chunk, and you can process that data within that callback function. In this case, you want to display that chunk in the terminal.

```js
function read(filePath) {
  const readableStream = fs.createReadStream(filePath);

  readableStream.on("data", (chunk) => {
     console.log("data is written");
    console.log(chunk);
  });

  readStream.on("open", () => {
  console.log("Stream opened...");
});

  readableStream.on("error", function (error) {
    console.log(`error: ${error.message}`);
  });

  readableStream.on("end", () => {
    console.log("Stream Closed...");
  });
}
```

The code also checks for errors by listening for the error event. When an error occurs, an error message will print to the terminal.

Based on the output above, you can see that the data was read in chunks or pieces, and these pieces of data are of the Buffer type.

For the sake of brevity, the terminal output above shows only two chunks, and the ellipsis indicates that there are several buffers in between the chunks shown here. The larger the file, the greater the number of buffers or chunks.

To return the data in a human-readable format, you will set the encoding type of the data by passing the string value of the encoding type you want as a second argument to the createReadStream() function.

```js
const readableStream = fs.createReadStream(filePath, 'utf8')
```

# Writing to a File with createWriteStream()

The createWriteStream function returns a writable file stream that you can write data to. Like the readable stream in the previous step, this writable stream emits a set of events like error, finish, and pipe. Additionally, it provides the write function for writing data to the stream in chunks or bits. The write function takes in the chunk, which could be a string, a Buffer, <Uint8Array>, or any other JavaScript value. It also allows you to specify an encoding type if the chunk is a string.

```js
function write(filePath) {
    const writableStream = fs.createWriteStream(filePath);

    writableStream.on('error',  (error) => {
        console.log(`An error occured while writing to the file. Error: ${error.message}`);
    });

    writableStream.on('finish', () => {
        console.log(`All your sentences have been written to ${filePath}`);
    })
}
```