## HTTP
When the browser sent a request to the server to get to our letsgosurfing.com page, it used a protocol known as HTTP (Hypertext Transfer Protocol), which defines how messages are formatted and transmitted, and what actions web servers and browsers should take in response to various commands.

## LONG POLLING

HTTP long-polling, which was the precursor to WebSockets. HTTP long-polling originated from the need to be able to send data to the client without the client first having to make a request. With HTTP long-polling, the client continually polls the server requesting new information. The server holds the request open until any new data is available, and responds with the new information once available. In essence, the client is constantly polling the server to see if the database has changed its state. As soon as the client receives that new information, it can immediately send another request and the operation is continually repeated.

Simply put, Long Polling involves making an HTTP request to a server and then holding the connection open to allow the server to respond later as per the server.

However, as you can imagine, this can get very taxing as the loop continues and the backend database grows. With more users pinging the server, this may take even longer. It is very expensive in terms of CPU, bandwidth consumption and storage. Every time a user makes an HTTP request, a bunch of headers and cookie data are transferred to the server. This can add up to a reasonably large amount of data that needs to be transferred, which in turn increases latency. So whatâ€™s the fix?